{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc3a2b3c",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>\"Викишоп\". Анализ токсичности комментариев с помощью BERT.<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Цель-и-задачи-проекта.\" data-toc-modified-id=\"Цель-и-задачи-проекта.-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Цель и задачи проекта.</a></span></li><li><span><a href=\"#Входные-данные.\" data-toc-modified-id=\"Входные-данные.-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Входные данные.</a></span><ul class=\"toc-item\"><li><span><a href=\"#Библиотеки.\" data-toc-modified-id=\"Библиотеки.-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Библиотеки.</a></span></li><li><span><a href=\"#Загрузка-и-обзор.\" data-toc-modified-id=\"Загрузка-и-обзор.-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Загрузка и обзор.</a></span></li></ul></li><li><span><a href=\"#Предобработка-текста.\" data-toc-modified-id=\"Предобработка-текста.-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Предобработка текста.</a></span><ul class=\"toc-item\"><li><span><a href=\"#Токенизация.\" data-toc-modified-id=\"Токенизация.-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Токенизация.</a></span></li><li><span><a href=\"#Выравнивание-длин-текстов.\" data-toc-modified-id=\"Выравнивание-длин-текстов.-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Выравнивание длин текстов.</a></span></li><li><span><a href=\"#Маска-&quot;внимания&quot;.\" data-toc-modified-id=\"Маска-&quot;внимания&quot;.-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>Маска \"внимания\".</a></span></li></ul></li><li><span><a href=\"#Создание-признаков-эмбеддингов-с-BERT.\" data-toc-modified-id=\"Создание-признаков-эмбеддингов-с-BERT.-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Создание признаков-эмбеддингов с BERT.</a></span></li><li><span><a href=\"#Обучение-моделей.-Выбор-лучшей.\" data-toc-modified-id=\"Обучение-моделей.-Выбор-лучшей.-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Обучение моделей. Выбор лучшей.</a></span><ul class=\"toc-item\"><li><span><a href=\"#Логистическая-регрессия.\" data-toc-modified-id=\"Логистическая-регрессия.-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>Логистическая регрессия.</a></span></li><li><span><a href=\"#Случайный-лес.\" data-toc-modified-id=\"Случайный-лес.-5.2\"><span class=\"toc-item-num\">5.2&nbsp;&nbsp;</span>Случайный лес.</a></span></li><li><span><a href=\"#Дамми-модель.\" data-toc-modified-id=\"Дамми-модель.-5.3\"><span class=\"toc-item-num\">5.3&nbsp;&nbsp;</span>Дамми-модель.</a></span></li><li><span><a href=\"#Выводы.\" data-toc-modified-id=\"Выводы.-5.4\"><span class=\"toc-item-num\">5.4&nbsp;&nbsp;</span>Выводы.</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c57e4b8",
   "metadata": {},
   "source": [
    "# Цель и задачи проекта."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de9e1279",
   "metadata": {},
   "source": [
    "Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию.\n",
    "\n",
    "`Дано:`\n",
    "\n",
    "Массив данных, включающий в себя 159571 комментарий пользователей, которые они оставляли к описаниям товаров на сайте \"Викишоп\". Для каждого комментария выставлен индикатор токсичности:  0 - комментарий нетоксичный, 1 - токсичный.\n",
    "\n",
    "`Цель:`\n",
    "\n",
    "Разработать инструмент - модель машинного обучения - который сможет определять токсичность новых комментариев, то есть классифицировать их на позитивные и негативные.\n",
    "\n",
    "`Задачи:`\n",
    "\n",
    "1. Посмотреть на датасет. Проверить на пропуски/повторы.\n",
    "2. Подготовить признаки для машинного обучения силами BERT.\n",
    "3. Обучить логистическую регрессию и случайный лес. Найти лучшую модель с лучшими гиперпараметрами и предложить её для классификации комментариев.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e3d29e3",
   "metadata": {},
   "source": [
    "# Входные данные."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b374c64",
   "metadata": {},
   "source": [
    "## Библиотеки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2abf1e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.dummy import DummyClassifier\n",
    "import torch\n",
    "import transformers\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from tqdm import notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf607153",
   "metadata": {},
   "source": [
    "## Загрузка и обзор."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47245e3d",
   "metadata": {},
   "source": [
    "Загрузим наш датасет. Здесь и далее в адресной строке указан локальный адрес расположения файлов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cef084de",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "\n",
    "    df = pd.read_csv(\"/Users/mihasia/Documents/Yandex_Practikum_Data_Science/Sprint_13(12)/toxic_comments.csv\")\n",
    "\n",
    "except:\n",
    "\n",
    "    df = pd.read_csv(\"/datasets/toxic_comments.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "157fb0cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159571 entries, 0 to 159570\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   text    159571 non-null  object\n",
      " 1   toxic   159571 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 2.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a1bb04",
   "metadata": {},
   "source": [
    "Много-много буков. Если мы собираемся использовать BERT, то такое количество текстов нам не осилить.\n",
    "\n",
    "Пропусков не наблюдается, что славно."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2696e294",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "268eb21e",
   "metadata": {},
   "source": [
    "Дубликатов тоже нет. Посмотрим на начинку датасета."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b30c73d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27058</th>\n",
       "      <td>Speedy Deletion \\n\\nPlease do not make personal attacks. Wikipedia has a strict policy against personal attacks. Attack pages and images are not tolerated by Wikipedia and are speedily deleted. Users who continue to create or repost such pages and images, especially those in violation of our Wikipedia:Biographies of living persons policy, will be blocked from editing Wikipedia. Thank you.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150995</th>\n",
       "      <td>\"\\n\\n Accolades \\n\\nRather than get into an edit-war, I'll post my opinion here about the so-called \"\"accolades\"\".  What we are talking about here is a nomination-for-a-nomination, not a nomination, and certainly not a win.  How is this notable? -''''''The '45 \"</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11302</th>\n",
       "      <td>\"\\n\\nFro anyone who cared to pay attention, it was obvious that \"\"eight and aces\"\" was a typo. \"\"Eights and Aces\"\" is correct. \"\"Aces and Eights\"\" is also valid.   ]] 00:12, 17 Sep 2004 (UTC)\\n\\n\"</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8030</th>\n",
       "      <td>I think this article is a little biased....  I don't particularly recall the old format being hugely popular.  I do know that I love 88.3's current format.  I can almost always turn it on and find a song I know.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72875</th>\n",
       "      <td>Anthem \\n\\nDid they play La Marsalles (sorry for the poor spelling) alongside God Save The Queen before the match due to the fact that the Dragons were French</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54481</th>\n",
       "      <td>}}}}}\\n\\n{{PageTabs\\n  |Talk page/\\n |Sanctions I am aware of Please place any GS or DS notices on this page\\n \\n |This={{{This|1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40548</th>\n",
       "      <td>Definitely this page is not written from a neutral point of view and has no citations whatsoever, the article needs a change of focus an citation from different sources.\\n\\n''''''(talk)</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4191</th>\n",
       "      <td>\"\\n\\n A beer for you! \\n\\n  good work your doing well   \"</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98554</th>\n",
       "      <td>IronRuby \\nJust wanted to note that IronRuby is not an web application framework like you added. This really might confuse people. I'll fix that one.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106645</th>\n",
       "      <td>\"\\nThanks ) Was rather interesting being in the news...  Zhang Help resolve disputes! \"</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                           text  \\\n",
       "27058   Speedy Deletion \\n\\nPlease do not make personal attacks. Wikipedia has a strict policy against personal attacks. Attack pages and images are not tolerated by Wikipedia and are speedily deleted. Users who continue to create or repost such pages and images, especially those in violation of our Wikipedia:Biographies of living persons policy, will be blocked from editing Wikipedia. Thank you.   \n",
       "150995  \"\\n\\n Accolades \\n\\nRather than get into an edit-war, I'll post my opinion here about the so-called \"\"accolades\"\".  What we are talking about here is a nomination-for-a-nomination, not a nomination, and certainly not a win.  How is this notable? -''''''The '45 \"                                                                                                                                    \n",
       "11302   \"\\n\\nFro anyone who cared to pay attention, it was obvious that \"\"eight and aces\"\" was a typo. \"\"Eights and Aces\"\" is correct. \"\"Aces and Eights\"\" is also valid.   ]] 00:12, 17 Sep 2004 (UTC)\\n\\n\"                                                                                                                                                                                                      \n",
       "8030    I think this article is a little biased....  I don't particularly recall the old format being hugely popular.  I do know that I love 88.3's current format.  I can almost always turn it on and find a song I know.                                                                                                                                                                                       \n",
       "72875   Anthem \\n\\nDid they play La Marsalles (sorry for the poor spelling) alongside God Save The Queen before the match due to the fact that the Dragons were French                                                                                                                                                                                                                                            \n",
       "54481   }}}}}\\n\\n{{PageTabs\\n  |Talk page/\\n |Sanctions I am aware of Please place any GS or DS notices on this page\\n \\n |This={{{This|1                                                                                                                                                                                                                                                                         \n",
       "40548   Definitely this page is not written from a neutral point of view and has no citations whatsoever, the article needs a change of focus an citation from different sources.\\n\\n''''''(talk)                                                                                                                                                                                                                 \n",
       "4191    \"\\n\\n A beer for you! \\n\\n  good work your doing well   \"                                                                                                                                                                                                                                                                                                                                                 \n",
       "98554   IronRuby \\nJust wanted to note that IronRuby is not an web application framework like you added. This really might confuse people. I'll fix that one.                                                                                                                                                                                                                                                     \n",
       "106645  \"\\nThanks ) Was rather interesting being in the news...  Zhang Help resolve disputes! \"                                                                                                                                                                                                                                                                                                                   \n",
       "\n",
       "        toxic  \n",
       "27058   0      \n",
       "150995  0      \n",
       "11302   0      \n",
       "8030    0      \n",
       "72875   0      \n",
       "54481   0      \n",
       "40548   0      \n",
       "4191    0      \n",
       "98554   0      \n",
       "106645  0      "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', -1)\n",
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a58a0520",
   "metadata": {},
   "source": [
    "Можно \"залипнуть\" на комментариях, помеченных единицей, поистине, ругательства и обзывательства порой впечатляют побольше заурядной похвалы. И нам предстоит научить компьютер их различать самостоятельно. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee15ace",
   "metadata": {},
   "source": [
    "# Предобработка текста."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37d0bf38",
   "metadata": {},
   "source": [
    "Как уже отмечалось выше, объём датасета \"неподъёмный\" для системы BERT, тем более на локальном слабом ноутбуке. Скрепя сердце вырежем из датасета 2000 рандомных объектов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dfac64e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# машина не потянет весь датасет, возьмём 2000 рандомных строк\n",
    "df = df.sample(2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae1b6600",
   "metadata": {},
   "source": [
    "При использовании BERT нам нужно сделать следующие предобработки:\n",
    "- токенизация\n",
    "- выравнивание длин текстов\n",
    "- создание маски \"внимания\" для распознавания нужных токенов"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a3c049",
   "metadata": {},
   "source": [
    "## Токенизация."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "126ee5e9",
   "metadata": {},
   "source": [
    "Итак, чтобы превратить тексты в токены, загрузим словарик из базы данных модели BERT. Мы будем использовать самый простой вариант, чтобы не перегружать память - \"bert-base-uncased\". Словарь был скачан [вот отсюда](https://huggingface.co/bert-base-uncased/tree/main) (файл `vocab.txt`) и загружен в проект по локальному пути.  \n",
    "\n",
    "Инициализируем токенизатор."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a4ed6d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    \n",
    "    tokenizer = transformers.BertTokenizer(\"/Users/mihasia/Documents/Yandex_Practikum_Data_Science/Sprint_13(12)/vocab2.txt\")\n",
    "\n",
    "except:\n",
    "    \n",
    "    tokenizer = transformers.BertTokenizer(\"https://huggingface.co/bert-base-uncased/blob/main/vocab.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95ef4ed8",
   "metadata": {},
   "source": [
    "Теперь сделаем преобразование текстов в номера токенов из словаря, загруженного выше. В процессе работы также было отмечено, что тексты превышают предельно допустимую в этом методе длину в 512 токенов, поэтому вынужденно устанавливаем ограничение, остальное при этом обрежется. Будем надеяться, что для обучения это не фатально, и моделям хватит и того, что есть."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a93f412f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# токенизируем наш срез датасета, обрезая слишком длинные тексты, чтобы пройти ограничение в 512\n",
    "tokenized = df[\"text\"].apply((lambda x: tokenizer.encode(x, add_special_tokens=True, truncation=True, max_length=512)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66cee7bd",
   "metadata": {},
   "source": [
    "## Выравнивание длин текстов."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0345c9f3",
   "metadata": {},
   "source": [
    "Как было уже отмечено, тексты попадаются разной длины, что неудивительно, как и наличие \"болтунов\" и людей \"меньше слов, больше дела!\". Исправим это недоразумение, тем более, что BERT обидится, если ему преподнести данные как-то иначе. \n",
    "\n",
    "Мы искусственно удлинним каждый текст до максимума (в нашем случае - 512), и в образовавшиеся ячейки-пустоты проставим нули."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "18c48eb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 512)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# сделаем длины токенизированных текстов одинаковыми и заполним нулями не занятые \"хвосты\"\n",
    "max_len = 0\n",
    "for i in tokenized.values:\n",
    "    if len(i) > max_len:\n",
    "        max_len = len(i)\n",
    "\n",
    "padded = np.array([i + [0]*(max_len-len(i)) for i in tokenized.values])\n",
    "padded.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b7f35c5",
   "metadata": {},
   "source": [
    "Отлично, размер датасета совпадает с ожидаемым. Идём дальше."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e6a7cca",
   "metadata": {},
   "source": [
    "## Маска \"внимания\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7367502",
   "metadata": {},
   "source": [
    "Маска внимания нужна, чтобы прикрыть то нулевое безобразие, что мы насоздавали в прошлом разделе проекта. Нужно, чтобы BERT исследовал только существенные токены, то есть те, которые были нашими изначальными текстами - вот и создадим для него матрицу из нулей и единиц такого же, как датасет, размера. Единицы в нём будут обозначать искомые токены."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9ef58b23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 512)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# создадим маску-шпаргалку для модели, чтобы ей было понятно: на проставленных выше нулях учиться не надо\n",
    "attention_mask = np.where(padded != 0, 1, 0)\n",
    "attention_mask.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e67020b1",
   "metadata": {},
   "source": [
    "Убедились, размер тот же. Вперёд!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4bbd8af",
   "metadata": {},
   "source": [
    "# Создание признаков-эмбеддингов с BERT."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11724064",
   "metadata": {},
   "source": [
    "Начнём с инициализации конфигурации и модели. Как и словарь токенов, эти файлы были получены [вот отсюда](https://huggingface.co/bert-base-uncased/tree/main) (файлы `config.json` и `pytorch_model.bin`, соответственно), и запущены в проект с локальной машины.\n",
    "\n",
    "При инициализации модели не забудем указать параметр конфигурации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a5e6b0ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    \n",
    "    config = transformers.BertConfig.from_json_file(\n",
    "    \"/Users/mihasia/Documents/Yandex_Practikum_Data_Science/Sprint_13(12)/config2.json\")\n",
    "    \n",
    "except:\n",
    "    \n",
    "    config = transformers.BertConfig.from_json_file(\n",
    "    \"https://huggingface.co/bert-base-uncased/blob/main/config.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2c038870",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at /Users/mihasia/Documents/Yandex_Practikum_Data_Science/Sprint_13(12)/pytorch_model2.bin were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    \n",
    "    model = transformers.BertModel.from_pretrained(\n",
    "    \"/Users/mihasia/Documents/Yandex_Practikum_Data_Science/Sprint_13(12)/pytorch_model2.bin\",\n",
    "    config=config)\n",
    "    \n",
    "except:\n",
    "    \n",
    "    model = transformers.BertModel.from_pretrained(\n",
    "    \"https://huggingface.co/bert-base-uncased/blob/main/pytorch_model.bin\",   \n",
    "    config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97b7c36d",
   "metadata": {},
   "source": [
    "Предупреждение, которое могло появиться после загрузки, гласит, что некоторые весы не были использованы при инициализации модели, и это ожидаемо, если мы используем BertForPreTraining модель. Мы её и используем, полагаю, всё в порядке.\n",
    "\n",
    "Приступаем к самой \"мясистой\" части работы. Нам предстоит запустить долгий цикл \"эмбеддингизации\" текстов, где за каждый цикл модель будет работать с батчем размером в 200 объектов. Затем мы слепим воедино полученные батчи с эмбеддингами, то есть векторными представлениями текстов - это и будут наши признаки для предсказаний токсичности."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "677f1f83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0688fad7672d4e0a831da0f0be994f06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# задаём размер батча\n",
    "batch_size = 200\n",
    "# создаём пустой лист для коллекционирования эмбеддингов\n",
    "embeddings = []\n",
    "# запускаем цикл батчами со счётчиком времени\n",
    "for i in notebook.tqdm(range(padded.shape[0]//batch_size)):\n",
    "    # делаем из данных тензоры (многомерные векторы)\n",
    "    batch = torch.LongTensor(padded[batch_size*i:batch_size*(i+1)])  \n",
    "    # указываем источник маски \"внимания\"\n",
    "    attention_mask_batch = torch.LongTensor(attention_mask[batch_size*i:batch_size*(i+1)])\n",
    "    # поясняем, что не нужен градиентный спуск, потому что будем обучаться потом отдельно\n",
    "    with torch.no_grad():\n",
    "        # собираем только \"нужные\", согласно маске, эмбеддинги из тензора\n",
    "        batch_embeddings = model(batch, attention_mask=attention_mask_batch)\n",
    "    # прилепляем эмбеддинги к общему списку\n",
    "    embeddings.append(batch_embeddings[0][:,0,:].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d840b9c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = np.concatenate(embeddings)\n",
    "#pd.DataFrame(features).to_csv(\"/Users/mihasia/Documents/Yandex_Practikum_Data_Science/Sprint_13(12)/features.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88726622",
   "metadata": {},
   "source": [
    "На локальной машине цикл считался полтора часа, это приличное время, но уменьшать датасет ещё сильнее не хотелось. Уменьшение размеров и увеличение количества батчей давало результат хуже описанного. Для страховки признаки были экспортированы, если вдруг не будет хватать времени на перезапуск всего кода."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f7c329c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>758</th>\n",
       "      <th>759</th>\n",
       "      <th>760</th>\n",
       "      <th>761</th>\n",
       "      <th>762</th>\n",
       "      <th>763</th>\n",
       "      <th>764</th>\n",
       "      <th>765</th>\n",
       "      <th>766</th>\n",
       "      <th>767</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.182341</td>\n",
       "      <td>0.206809</td>\n",
       "      <td>-0.362974</td>\n",
       "      <td>0.451316</td>\n",
       "      <td>0.213900</td>\n",
       "      <td>0.102443</td>\n",
       "      <td>0.035701</td>\n",
       "      <td>0.557241</td>\n",
       "      <td>-0.203374</td>\n",
       "      <td>0.287266</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.182744</td>\n",
       "      <td>0.162574</td>\n",
       "      <td>0.410327</td>\n",
       "      <td>-0.116449</td>\n",
       "      <td>0.294475</td>\n",
       "      <td>0.230649</td>\n",
       "      <td>-0.293169</td>\n",
       "      <td>-0.068288</td>\n",
       "      <td>0.685881</td>\n",
       "      <td>0.587387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.474841</td>\n",
       "      <td>-0.030300</td>\n",
       "      <td>0.352599</td>\n",
       "      <td>-0.094763</td>\n",
       "      <td>-0.142603</td>\n",
       "      <td>-0.632908</td>\n",
       "      <td>-0.086629</td>\n",
       "      <td>0.230572</td>\n",
       "      <td>-0.204094</td>\n",
       "      <td>-0.689256</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.005922</td>\n",
       "      <td>-0.308224</td>\n",
       "      <td>0.128605</td>\n",
       "      <td>-0.420191</td>\n",
       "      <td>-0.044927</td>\n",
       "      <td>0.531814</td>\n",
       "      <td>-0.044234</td>\n",
       "      <td>-0.702617</td>\n",
       "      <td>0.083213</td>\n",
       "      <td>0.165290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.227460</td>\n",
       "      <td>-0.082311</td>\n",
       "      <td>-0.335135</td>\n",
       "      <td>0.084723</td>\n",
       "      <td>-0.679311</td>\n",
       "      <td>-0.643975</td>\n",
       "      <td>0.523805</td>\n",
       "      <td>0.801702</td>\n",
       "      <td>0.201131</td>\n",
       "      <td>-0.359601</td>\n",
       "      <td>...</td>\n",
       "      <td>0.109084</td>\n",
       "      <td>-0.198109</td>\n",
       "      <td>0.169481</td>\n",
       "      <td>-0.310461</td>\n",
       "      <td>0.160826</td>\n",
       "      <td>0.035175</td>\n",
       "      <td>-0.128213</td>\n",
       "      <td>-0.219390</td>\n",
       "      <td>0.371376</td>\n",
       "      <td>0.692709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.218693</td>\n",
       "      <td>-0.194800</td>\n",
       "      <td>-0.245334</td>\n",
       "      <td>0.197041</td>\n",
       "      <td>-0.056888</td>\n",
       "      <td>-0.514260</td>\n",
       "      <td>0.839216</td>\n",
       "      <td>0.281435</td>\n",
       "      <td>0.240447</td>\n",
       "      <td>-0.318882</td>\n",
       "      <td>...</td>\n",
       "      <td>0.305383</td>\n",
       "      <td>-0.000331</td>\n",
       "      <td>0.039010</td>\n",
       "      <td>-0.045343</td>\n",
       "      <td>0.333013</td>\n",
       "      <td>0.180759</td>\n",
       "      <td>-0.026365</td>\n",
       "      <td>-0.201529</td>\n",
       "      <td>0.777940</td>\n",
       "      <td>0.327623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.144419</td>\n",
       "      <td>0.226945</td>\n",
       "      <td>-0.255751</td>\n",
       "      <td>0.054216</td>\n",
       "      <td>-0.315064</td>\n",
       "      <td>-0.611658</td>\n",
       "      <td>0.632851</td>\n",
       "      <td>0.410951</td>\n",
       "      <td>-0.197194</td>\n",
       "      <td>-0.620301</td>\n",
       "      <td>...</td>\n",
       "      <td>0.707762</td>\n",
       "      <td>-0.256246</td>\n",
       "      <td>0.075699</td>\n",
       "      <td>-0.317784</td>\n",
       "      <td>0.699774</td>\n",
       "      <td>0.006987</td>\n",
       "      <td>-0.619489</td>\n",
       "      <td>-0.092781</td>\n",
       "      <td>0.800038</td>\n",
       "      <td>0.153542</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 768 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  0.182341  0.206809 -0.362974  0.451316  0.213900  0.102443  0.035701   \n",
       "1 -0.474841 -0.030300  0.352599 -0.094763 -0.142603 -0.632908 -0.086629   \n",
       "2  0.227460 -0.082311 -0.335135  0.084723 -0.679311 -0.643975  0.523805   \n",
       "3  0.218693 -0.194800 -0.245334  0.197041 -0.056888 -0.514260  0.839216   \n",
       "4 -0.144419  0.226945 -0.255751  0.054216 -0.315064 -0.611658  0.632851   \n",
       "\n",
       "          7         8         9  ...       758       759       760       761  \\\n",
       "0  0.557241 -0.203374  0.287266  ... -0.182744  0.162574  0.410327 -0.116449   \n",
       "1  0.230572 -0.204094 -0.689256  ... -0.005922 -0.308224  0.128605 -0.420191   \n",
       "2  0.801702  0.201131 -0.359601  ...  0.109084 -0.198109  0.169481 -0.310461   \n",
       "3  0.281435  0.240447 -0.318882  ...  0.305383 -0.000331  0.039010 -0.045343   \n",
       "4  0.410951 -0.197194 -0.620301  ...  0.707762 -0.256246  0.075699 -0.317784   \n",
       "\n",
       "        762       763       764       765       766       767  \n",
       "0  0.294475  0.230649 -0.293169 -0.068288  0.685881  0.587387  \n",
       "1 -0.044927  0.531814 -0.044234 -0.702617  0.083213  0.165290  \n",
       "2  0.160826  0.035175 -0.128213 -0.219390  0.371376  0.692709  \n",
       "3  0.333013  0.180759 -0.026365 -0.201529  0.777940  0.327623  \n",
       "4  0.699774  0.006987 -0.619489 -0.092781  0.800038  0.153542  \n",
       "\n",
       "[5 rows x 768 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test = pd.read_csv(\"/Users/mihasia/Documents/Yandex_Practikum_Data_Science/Sprint_13(12)/features.csv\")\n",
    "pd.DataFrame(features).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bbb9cab",
   "metadata": {},
   "source": [
    " Признаки готовы. Целевой признак был готовенький сразу. Пошли учиться."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "109aff77",
   "metadata": {},
   "source": [
    "# Обучение моделей. Выбор лучшей."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9fc7706",
   "metadata": {},
   "source": [
    "Традиционное действо перед обучением - разделение выборки на обучающую и тестовую. Поделим 3 к 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "acf7f42a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = features\n",
    "y = df.toxic.values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c2e043",
   "metadata": {},
   "source": [
    "## Логистическая регрессия."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b2e9543",
   "metadata": {},
   "source": [
    "Попробуем логистическую регрессию для наших признаков. Чтобы как-то ей помочь, сделаем перебор одного из параметров - силы регуляризации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c0fe890a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters:  {'C': 5.263252631578947}\n",
      "best scores:  0.932\n"
     ]
    }
   ],
   "source": [
    "parameters = {'C': np.linspace(0.0001, 100, 20)}\n",
    "grid_search = GridSearchCV(LogisticRegression(), parameters)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print('best parameters: ', grid_search.best_params_)\n",
    "print('best scores: ', grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e5478b5",
   "metadata": {},
   "source": [
    "Отлично, тогда зададим этот параметр и обучим модель."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a64720b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=5.26)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LR = LogisticRegression(C=5.26)\n",
    "LR.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dd0d92d",
   "metadata": {},
   "source": [
    "Теперь проверим, насколько качественно предсказываются ответы для обучающей и тестовой выборок, посчитав метрику accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ed5cb150",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for train: 1.0\n",
      "Accuracy for test: 0.928\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy for train:\", LR.score(X_train, y_train))\n",
    "print(\"Accuracy for test:\", LR.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b99f18",
   "metadata": {},
   "source": [
    "Неплохо!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fc60f17",
   "metadata": {},
   "source": [
    "## Случайный лес."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a421f84",
   "metadata": {},
   "source": [
    "Метрики и так вполне хороши, но почему бы не попробовать ещё одну модель. Подберём глубину и количество деревьев и посмотрим, какая точность классификации получится здесь."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "054c15c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters:  {'max_depth': 21.0, 'n_estimators': 45}\n",
      "best scores:  0.9179999999999999\n"
     ]
    }
   ],
   "source": [
    "parameters = {'max_depth': np.linspace(1, 21, 2), 'n_estimators': np.linspace(1, 101, 10).astype(int)}\n",
    "grid_search = GridSearchCV(RandomForestClassifier(), parameters)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print('best parameters: ', grid_search.best_params_)\n",
    "print('best scores: ', grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e02dcb64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=21, n_estimators=34, random_state=42)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RFC = RandomForestClassifier(max_depth=21, n_estimators=34, random_state=42)\n",
    "RFC.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9b33a5be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for train: 1.0\n",
      "Accuracy for test: 0.908\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy for train:\", RFC.score(X_train, y_train))\n",
    "print(\"Accuracy for test:\", RFC.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4be7873",
   "metadata": {},
   "source": [
    "Слегка похуже, чем у логистической регрессии."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a59acdf1",
   "metadata": {},
   "source": [
    "## Дамми-модель."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7537df5",
   "metadata": {},
   "source": [
    "Напоследок убедимся, что классификаторы наши вообще-то вполне адекватны. Запустим дамми-модель на наших данных и посмотрим на score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "15960d85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for train: 0.904\n",
      "Accuracy for test: 0.892\n"
     ]
    }
   ],
   "source": [
    "DC = DummyClassifier()\n",
    "DC.fit(X_train, y_train)\n",
    "\n",
    "print(\"Accuracy for train:\", DC.score(X_train, y_train))\n",
    "print(\"Accuracy for test:\", DC.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f906a124",
   "metadata": {},
   "source": [
    "Здесь всё выглядит не очень даже для обучающей выборки."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "391d369f",
   "metadata": {},
   "source": [
    "## Выводы."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53c4e315",
   "metadata": {},
   "source": [
    "1. BERT очень долгий, но он того стоит. Он сам \"подчистил\" тексты и сам сделал адекватные для обучения признаки.\n",
    "2. Протестирована всего пара простых моделей для классификации, но среди них уже есть отличные варианты.\n",
    "3. Лучший вариант - логистическая регрессия с \"подкрученным\" параметром регуляризации.\n",
    "4. Ругаться в интернете - нехорошо. Приходится тратить время на такие проекты, чтобы эти ругательства потом подчищать. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "\"Викишоп\". Анализ токсичности комментариев с помощью BERT.",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
